# ğŸ¥ Claim Denial Risk Prediction Pipeline

**Live API**  
ğŸ‘‰ https://claim-denial-risk-pipeline.onrender.com

---

## ğŸ“Œ Business Problem

Healthcare insurance claims are frequently denied due to administrative, clinical, or policy-related reasons. Claim denials lead to delayed reimbursements, increased operational costs, and poor provider experience.

The objective of this project is to **predict the likelihood of a claim being denied** before adjudication so that high-risk claims can be prioritized for review and corrective action.

---

## ğŸ¯ Solution Overview

This project implements a **production-style machine learning pipeline** that:

- Engineers healthcare-specific features from raw claim data  
- Trains a class-imbalance-aware Logistic Regression model  
- Supports **batch scoring** and **real-time API inference**  
- Uses a single sklearn pipeline to avoid trainingâ€“serving skew  
- Is containerized using Docker and deployed on the cloud  

---

## ğŸ— Architecture Diagram

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Incoming Claim Data  â”‚
               â”‚ (API request / CSV)    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Feature Engineering Pipeline â”‚
             â”‚ (Custom sklearn Transformer)â”‚
             â”‚                             â”‚
             â”‚ â€¢ Length of stay flags      â”‚
             â”‚ â€¢ Age buckets               â”‚
             â”‚ â€¢ Insurance risk flags      â”‚
             â”‚ â€¢ Provider experience flags â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Preprocessing Pipeline           â”‚
           â”‚                                 â”‚
           â”‚ â€¢ Numeric imputation + scaling  â”‚
           â”‚ â€¢ Categorical encoding          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ ML Model                          â”‚
          â”‚ Logistic Regression               â”‚
          â”‚ (class_weight = balanced)         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Output                                   â”‚
    â”‚ â€¢ Denial prediction (0 / 1)              â”‚
    â”‚ â€¢ Denial risk probability                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

## ğŸ“Š Model Performance Summary

Due to strong class imbalance (few denied claims), recall and risk ranking were prioritized over raw accuracy.

| Model | Accuracy | Precision | Recall | ROC-AUC |
|-----|----------|-----------|--------|--------|
| Random Forest | High | Low | Low | ~0.50 |
| **Logistic Regression (selected)** | Moderate | Low | **Higher** | ~0.49 |

### Why Logistic Regression?
- Better recall on denied claims  
- More stable probability outputs  
- Easier interpretability for risk scoring use cases  

---

## ğŸ§ª Data Leakage Prevention

- Only pre-adjudication features are used  
- No post-outcome signals included  
- Feature logic is embedded inside the pipeline  
- Same transformations are applied during:
  - Training
  - Batch scoring
  - Real-time inference  

---

## âš–ï¸ Class Imbalance Handling

- Used `class_weight="balanced"`  
- Evaluated recall and ROC-AUC  
- Threshold tuning performed to optimize business relevance  

---

## ğŸš€ Deployment

### ğŸ”¹ Real-Time API (FastAPI)

- Endpoint: `/predict`
- Accepts raw claim attributes as JSON
- Returns denial prediction and probability

Swagger UI:

---

### ğŸ”¹ Batch Scoring

- New claims placed in `data/incoming/`
- Scheduled execution via Windows Task Scheduler
- Outputs scored claims with denial probability

---

## ğŸ³ Docker & Cloud Deployment

- Application packaged using Docker
- Trained model artifact included in container
- Deployed as a cloud service on Render

**Production Note:**  
In real enterprise environments, model artifacts are typically loaded from object storage or a model registry rather than committed to source control.

---

## ğŸ“ Project Structure


```
claim-denial-risk-pipeline/
â”‚
â”œâ”€â”€ api/                          # FastAPI application
â”‚   â”œâ”€â”€ app.py                    # Main FastAPI app with prediction endpoints
â”‚   â”œâ”€â”€ schemas.py                # Pydantic models for request/response
â”‚   â””â”€â”€ utils.py                  # Helper functions for API
â”‚
â”œâ”€â”€ src/                          # Training, feature pipeline, batch scoring
â”‚   â”œâ”€â”€ train_model.py            # Model training script
â”‚   â”œâ”€â”€ feature_pipeline.py       # Feature engineering pipeline
â”‚   â”œâ”€â”€ batch_score.py            # Batch inference for multiple claims
â”‚   â”œâ”€â”€ data_loader.py            # Data loading utilities
â”‚   â”œâ”€â”€ utils.py                  # Helper functions
â”‚   â””â”€â”€ __init__.py               # Package initialization
â”‚
â”œâ”€â”€ models/                       # Trained ML model
â”‚   â”œâ”€â”€ claim_denial_model.pkl    # Serialized trained model
â”‚   â””â”€â”€ scaler.pkl                # Feature scaler (if applicable)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Original raw data
â”‚   â”‚   â””â”€â”€ claims_data.csv
â”‚   â”œâ”€â”€ processed/                # Cleaned and processed data
â”‚   â”‚   â””â”€â”€ processed_claims.csv
â”‚   â”œâ”€â”€ incoming/                 # New claims for batch inference
â”‚   â”‚   â””â”€â”€ new_claims.csv
â”‚   â””â”€â”€ output/                   # Scored outputs
â”‚       â””â”€â”€ scored_claims.csv
â”‚
â”œâ”€â”€ config/                       # YAML configuration
â”‚   â””â”€â”€ config.yaml               # Feature names, model parameters
â”‚
â”œâ”€â”€ notebooks/                    # EDA and experimentation
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore file
â”œâ”€â”€ README.md                     # Project documentation
â””â”€â”€ mlflow.db                     # MLflow experiment tracking (auto-generated)
```


---

## ğŸ§  Skills Demonstrated

- End-to-end ML pipeline design  
- Healthcare feature engineering  
- Handling imbalanced datasets  
- MLflow experiment tracking  
- Batch and real-time inference  
- FastAPI  
- Docker  
- Cloud deployment  

---

## ğŸ”— Live Demo

ğŸ‘‰ https://claim-denial-risk-pipeline.onrender.com/docs

---

## âœ… Project Status

âœ” Model trained  
âœ” Batch scoring implemented  
âœ” Real-time API deployed  
âœ” Dockerized and cloud hosted  
